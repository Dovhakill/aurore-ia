# main.py - Version 1.1 du bot Aurore
# Inclut l'extraction d'image et la g√©n√©ration d'index via template.

import os
import requests
from bs4 import BeautifulSoup
from github import Github
from jinja2 import Environment, FileSystemLoader, select_autoescape
from dotenv import load_dotenv

# Charger les variables d'environnement (API keys, etc.)
load_dotenv()

GNEWS_API_KEY = os.getenv('GNEWS_API_KEY')
GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')
TARGET_REPO_NAME = "Horizon-Network/horizon-tech-site" # Exemple

def get_article_details(article_url):
    """
    Extrait le titre, le r√©sum√© et l'URL de l'image d'un article source.
    Retourne un dictionnaire avec les d√©tails, ou None en cas d'√©chec.
    """
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(article_url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        # Extraire le titre propre
        title = soup.find('title').text.split('|')[0].strip()

        # Extraire la description
        description_tag = soup.find('meta', attrs={'name': 'description'})
        summary = description_tag['content'] if description_tag else "Lire l'article pour en savoir plus."

        # Logique d'extraction de l'image (og:image > premi√®re image > d√©faut)
        og_image = soup.find('meta', property='og:image')
        if og_image and og_image.get('content'):
            image_url = og_image['content']
        else:
            main_content = soup.find('article') or soup.find('main') or soup.body
            first_img = main_content.find('img') if main_content else None
            if first_img and first_img.get('src'):
                # Construire une URL absolue si n√©cessaire
                image_url = requests.compat.urljoin(article_url, first_img['src'])
            else:
                # IMPORTANT: Cette image doit exister dans le d√©p√¥t du site
                image_url = 'assets/default-image.jpg' 

        return {
            "title": title,
            "summary": summary,
            "image_url": image_url,
            "url": article_url, # L'URL source pour r√©f√©rence
            "date": "04/09/2025" # Placeholder, √† dynamiser
        }
    except Exception as e:
        print(f"ERREUR - Impossible de parser {article_url}: {e}")
        return None

def main():
    """
    Fonction principale orchestrant le workflow du bot.
    """
    print("D√©marrage du bot Aurore V1.1...")

    # --- 1. R√©cup√©ration des articles (simulation) ---
    # Ici, tu aurais ton appel √† l'API GNews. 
    # Pour l'exemple, on utilise une liste statique.
    articles_to_process = [
        # Remplace √ßa par tes vrais articles GNews
        {"title": "Un nouvel article sur l'IA", "url": "https://www.example.com/article1"},
        {"title": "La blockchain du futur", "url": "https://www.example.com/article2"},
        # ... jusqu'√† 10 articles
    ]
    
    print(f"{len(articles_to_process)} articles √† traiter.")
    
    # --- 2. Traitement des articles et collecte des donn√©es ---
    articles_data_for_index = []
    
    # On ajoute manuellement notre article d'enqu√™te en t√™te de liste !
    # C'est la "rustine" propre pour l'int√©grer au flux automatis√©.
    investigation_details = get_article_details("URL_DE_TON_ARTICLE_SOURCE_POUR_LENQUETE") # Remplace par une vraie URL source
    if investigation_details:
        # On ajuste les d√©tails pour notre article sp√©cial
        investigation_details['title'] = "Op√©ration 'Cochon √† l'Engrais' : D√©mant√®lement d'une arnaque crypto"
        investigation_details['url'] = "articles/enquete-arnaque-pig-butcherin.html" # Lien local
        investigation_details['date'] += " üîπ INVESTIGATION"
        articles_data_for_index.append(investigation_details)

    for article in articles_to_process:
        details = get_article_details(article['url'])
        if details:
            # Ici, tu g√©n√©rerais et pousserais la page HTML de l'article individuel
            # ...
            # Puis tu ajoutes ses donn√©es √† la liste pour l'index
            articles_data_for_index.append(details)

    if not articles_data_for_index:
        print("Aucune donn√©e d'article collect√©e. Arr√™t.")
        return

    # --- 3. G√©n√©ration et publication du nouvel index.html ---
    print("G√©n√©ration du nouveau index.html...")
    
    # Connexion √† GitHub
    g = Github(GITHUB_TOKEN)
    repo = g.get_repo(TARGET_REPO_NAME)

    # R√©cup√©ration du contenu du template depuis le d√©p√¥t
    template_content = repo.get_contents("templates/index_template.html").decoded_content.decode('utf-8')
    
    # Configuration de Jinja2 pour charger le template depuis une cha√Æne
    env = Environment(loader=FileSystemLoader('.'), autoescape=select_autoescape(['html']))
    template = env.from_string(template_content)

    # S√©paration des donn√©es pour le template
    featured_article = articles_data_for_index[0]
    latest_articles = articles_data_for_index[1:10] # On s'assure de n'en prendre que 9 autres

    # Rendu du HTML final
    rendered_html = template.render(
        featured_article=featured_article,
        latest_articles=latest_articles
    )

    # Publication sur GitHub
    try:
        index_file = repo.get_contents("index.html")
        repo.update_file(
            index_file.path,
            "MAJ AUTO: Reconstruction de l'index par Aurore V1.1",
            rendered_html,
            index_file.sha
        )
        print("SUCC√àS - index.html a √©t√© mis √† jour dans le d√©p√¥t.")
    except Exception as e:
        print(f"ERREUR - Impossible de mettre √† jour index.html: {e}")


if __name__ == "__main__":
    main()
